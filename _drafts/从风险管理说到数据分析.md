从风险管理说到数据分析

# 题由

> 本文是开专栏后的第一篇文章，主要讲笔者从一个风险管理从业者走上数据分析这条路的一些历程以及这个过程中的一些思考，最终将介绍下这个专栏的初步写作计划。
今年是进入这个行当的第七个年头，在前四个年头里，我从贷前的尽职调查做到贷后的应收账款管理。印象中的入门是从信用风险管理理论里的5C（Character、Capacity、Capital、Collateral、Condition)，5P（Personal、Purpose、Payment、Protection、Perspective）开始的。面对形形色色的借款人，在尽调报告里总试图将每一笔贷款纳入这些5C、5P框架进行分析。
做得久了慢慢意识到，我们所面对的风险远不是几个框架可以界定的，而每一个风险因素之间也不是相互孤立的：在说到客户资产及担保的时候，产权的界定、资产的价值、抵押的效力、折现的难易以及执行的成本等不断地纳入认知范围；说到贷款的用途时，开始去探究实际的借款人、追踪相关的合同、核算项目的投入、辨识借款人的假戏真言；关心还款来源的时候，发现一张张报表背后有太多财务知识和业务常识需要去掌握；谁又没见过几个假流水，谁又没摸过几个假房本。

从经济到财务，从政策到法律，每一个风险从业人员每天都在处理这些信息。印象中我司的法人尽调报告是24页纸的模板，当然对于我们来说洋洋洒洒几万字算得了什么。最后绞尽脑汁的却是最后那几百个字，虽然我们早就想好了格式，风险点在脑袋里倒腾来倒腾去也不超过那20项；但是我们仍然会陷于一些纠结中，我们试图给每一条一个权重在脑海里拟合，然后精准地表达我们专业的意见。

后来我管理着几个亿的应收账款，对着台账时不时能像放电影一样去回放以前调查过得哪些贷款，我总是能浮现出那些在我面前晃荡而过的客户：有的人虚情假意地笑，有的人敬小慎微地看着合同，有的人滔滔不绝地在饭桌上讲，有的人换着法子套近乎，我给这些人像写传记一样地留下了24页纸，我曾反复掂量着一个人的好与坏，回过神来却只剩眼前确实台账上那些冰冷的数字。

也是因为这一张张excel表里的数字，开始让我思考一个问题：有没有一种方法能让我在写最后那几百个字的时候不那么犹豫；或者说我那天心情不好的时候，写完前面22页纸后，有人已经自动帮我把最后一页自动写好了。

工欲善其事，必先利其器。在朋友的推荐下，一个计算机没过二级，统计学、概率论与数理统计早已还给老师的商科生走上了数据分析这条搬砖路。都说人生苦短，我用Python，所以我将分析语言选定在了Python。当然在目前的工作中，是Python+MySQL+Excel的组合。

鉴于自己的学习过程，在这个专栏里，我计划先从分析工具的使用、数据的预处理、基于业务逻辑的数据分析以及风险建模这些步骤一步步写过去。也就是说，下一篇将主要将Python在数据分析中的使用走马观花式的跑一遍，为了贴合风控业务，我选择将Lending Club的公开数据作为分析对象。

# 数据准备

- 我希望通过两到三篇文章的方式，把Python在整个信贷数据分析的各个环节的使用做一个走马观花式的介绍。
- 为贴合实际，数据采用Lending Club的公开数据,如有需要请点击下载
- 数据分析工具主要是Python3及Numpy,Pandas等科学计算包，数据可视化采用Python上最常用的Matplotlib及Seaborn
- 考虑受众，决定把Jupyter Notebook上的代码和分析全部贴过来，所以篇幅比较长，不喜勿进。

1. 导入包

```
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(context='notebook',style="ticks",palette="GnBu_d",font_scale=1.5,font='ETBembo',rc={"figure.figsize": (10, 6)})
#plt.rcParams['figure.figsize']=(15,10)
import warnings
warnings.filterwarnings('ignore') #为了整洁，去除弹出的warnings
pd.set_option('precision', 5) #设置精度
pd.set_option('display.float_format', lambda x: '%.5f' % x) #为了直观的显示数字，不采用科学计数法
pd.options.display.max_rows = 200 #最多显示200行
```

2. 初始化pandas

- 分析数据我把它放在Jupyter Notebook的根目录
- 原始数据以CSV的形式存储，所以这里要讲到pandas.read_csv这个常用的方法将数据读入DataFrame,它的所有参数详见这里

```
data = pd.read_csv('LoanStats_securev1_2016Q1.csv',skiprows=0,header=1)
```

3. 查看数据全貌

```
print(data.shape)
print(data.head(3))
print(data.columns)

```

> 首先对于object这类非数值变量，pandas的describe方法会给出变量的：‘非空值数量’、‘unique数量’、‘最大频数变量’、‘最大频数’，为了直观的观测缺失情况，我在后面添加了‘缺失值比重’。

```
print(data.select_dtypes(include=['O']).describe().T.assign(missing_pct=data.apply(lambda x : (len(x)-x.count())/len(x))))
```

- 观测上面24个非数值变量，首先可以发现‘desc’借款描述、‘verification_status_joint’共同借款人收入水平验证这两个变量缺失率95%以上，这其实也符合逻辑，p2p平台当然希望客户披露的信息越多越对称，但是很多非强制披露的借款人总是倾向沉默，对于分析来讲，这部分变量由于缺失率太高就不纳入后续进一步分析了，当然也有一种情况，就是如果把变量转化成空或非空这种布尔变量，非空的部分区分能力非常强也是可以继续纳入分析

- 直接观测返回结果，我们也可以对Lending Club2016年一季度的业务状况有一部分了解，比如借款期限分布最多的是36个月，利率分布最多的是11.9%，信用评级以B级居多，借款人职业中分布最大的竟然是教师（不过占比很小，总共有4万多个职业在平台申请借款，也不知道这种申请数据，比如职业，在米国是否验证），就业年限里10年以上的竟然占到了34.7%！房子以抵押贷款为主，贷款的用途里大部分是债务合并借新还旧，等等

- 这其实就是一个简单的用户画像，了解分析的对象到底是哪群人，对于风控领域来讲，很多的预测分析说到底就是假设某一群人在一定时间内会有相同的行为模式，所以用户画像是保障分析准确的重要前提

> 查看分位数
```
print(data.select_dtypes(include = ['float64']).describe().T.assign(missing_pct = data.apply(lambda x : (len(x) - x.count()) / len(x)),\
    nunique = data.apply(lambda x : x.nunique()), \
    pct_10 = data.select_dtypes(include = ['float64']).apply(lambda x : x.dropna().quantile(0.1)), \
    pct_20 = data.select_dtypes(include = ['float64']).apply(lambda x : x.dropna().quantile(0.2)), \
    pct_50 = data.select_dtypes(include = ['float64']).apply(lambda x : x.dropna().quantile(0.5)), \
    pct_80 = data.select_dtypes(include = ['float64']).apply(lambda x : x.dropna().quantile(0.8))))
```

> 在变量不多的情况下，更直观的可以采用盒状图来展示,下面选包含'num'的变量进行展示,这里有个方便的方法就是.loc[:,data.columns.str.contains('amnt')],其中.loc方法参数详见链接1，.str.contains方法的参数详见链接2

```
demo_data = data.loc[:, data.columns.str.contains("amnt")]
sns.boxplot(data = demo_data)
plt.show()
```

> 其他

- Lending Club的借款额最小是1000美元，最大40000美元，平均在14000-15000美元左右，和我们的小额贷款金额差不多，甚至更小一些，
借款人每月还款金额主要在200-600美元之间，借款人自身提供的年收入，平均约8万美元，主要集中在5万美元和9.5万美元之间，不过根据美国社会保障管理局数据,美国人均年收入约4.4万美元，无论怎么说，根据债务收入比（DTI），Lending Club把它控制在35%以下，平均在18%-20%，整体控制在比较合理的水平，
- 再来看对美国人非常重要的FICO分，Base FICO Scores是在300到850分之间，而Lending Club的客户分值控制在660以上，主要是670-710之间,应该说这群人信用记录并不是特别优秀的，这是一个逆向选择的过程，12%的利率放在中国的P2P不算高，但是愿意承担12%的利率的人本身就限定了这群人的质量，后续适合和利率放在一起分析信用评分对定价的影响，

![image](https://pic1.zhimg.com/4b19dea1d40f73dd91ee9aa24799aac4_b.png)

- 有个变量叫open_acc,意思是目前有授信的账户数，放在我朝类似于一个人有信用卡的数量或者说也包含其他P2P的授信账户的数量，对于做风控的人来讲其实比较关心这个数据，太少了说明没有信用记录，太多了意味着很大几率过度授信。放在我们的互联网金融角度看，现在P2P平台这么多，而且基本上没有进央行征信，理论上客户想去其他平台，其他平台很难知道，所以专门有些反欺诈的数据商提供借款人的‘多平台借款信息’，以解决信息不对称的问题。在Lend Club数据中，平均账户数达到12个，后续适合与FICO分放在一起分析账户数对评分的影响，
不良记录，从pub_rec、bankrupt、以及包含pd(past due)的变量可以看出，这些记录在Lending Club几乎是KO规则，有不良记录基本上没法贷款，单独拿出这条说，其实是我一直期望我国也能有一个更加完善的社会信用体系，比如我们的失信被执行人（俗称老赖）这些失信记录的公开也算是一种进度，很多金融机构也会直接把失信被执行人KO掉，这本身是一种失信惩戒，间接提高借款人的违约成本，
- 考虑主题是讲Python的应用，关于变量的数据层面的统计值分析及其业务层面的一些理解就到这里吧，后面开始对重要的几个变量数据预处理后进行详细的分析

# 业务层面的分析

> 我们在原始数据中挑选出变量进行分析，本文只分析放款用户，故而把issue_d这个变量为空的去掉，此外，只选取2011年的数据进行分析(数据包括了2007-2011)。并进行了数据预处理

```
analysis_columns=['issue_d','term','int_rate','grade','home_ownership','verification_status','purpose','loan_amnt','total_pymnt','out_prncp',
                  'total_rec_int','total_rec_prncp','installment','annual_inc','dti','fico_range_low','fico_range_high','last_fico_range_low',
                  'last_fico_range_high', 'open_acc','loan_status','delinq_amnt','acc_now_delinq','tot_coll_amt']
analysis_data = (data.loc[data.issue_d.notnull(),analysis_columns])\
                     .assign(month=lambda x: pd.to_datetime(x['issue_d']).dt.month,
                             year = lambda x: pd.to_datetime(x['issue_d']).dt.year,
                             interest_rate = lambda x:x['int_rate'].str.strip('%'),
                             fico_change = lambda x :  (x['last_fico_range_high']-x['fico_range_high']))
analysis_data = analysis_data[analysis_data.year == 2011]
print(analysis_data.head())
```

1. 贷款次数及贷款金额

```
perform_data = analysis_data.groupby('month')['loan_amnt'].agg(['count','sum'])

f, (ax1, ax2) = plt.subplots(2, 1, sharex = True)
x = perform_data.index
sns.barplot(x, perform_data["count"], ax = ax1)
sns.barplot(x, perform_data["sum"], ax = ax2)
ax1.set_xlabel("")
ax1.set_ylabel("loan_count")
ax2.set_ylabel("loan_amount")
sns.despine(bottom = True)
plt.show()


from scipy.stats import norm
sns.distplot(analysis_data.loan_amnt, fit = norm, kde = True)
plt.show()

analysis_data.term.value_counts().plot.pie(figsize = (10, 10))
plt.show()

sns.distplot(analysis_data.interest_rate.astype(float),fit=norm,kde=True)
sns.despine(top=True)
plt.show()

sns.countplot(y=analysis_data.purpose) # 贷款目的
sns.despine(top=True)
plt.show()
```

> 可以看出，逐月都在上升；此外，贷款金额右偏

2. 资产质量

> 在这里我狭义地理解为在一定时期、利率、期限结构下资产所能来带的收益高低或损失可能，对于贷款来说，借款人偿还本息的及时和足额程度、借款人的信用等级、贷款的利率和期限等等都影响到资产的质量。不过要注意，由于借款时间是2016年1季度，而从LC的数据上看，观测点应该是6月初，也就是最短的观测期才2个月，通常我们认为借款人的还款观察期最好是在6月到12个月，因为在这个期限内，借款人还款的表现情况才逐渐趋于稳定。

```
groupd_mth =  analysis_data.groupby(['month','loan_status'])
pay_data = groupd_mth.agg({'loan_amnt':'sum','out_prncp':'sum','total_rec_prncp':'sum','total_rec_int':'sum'}) \
                     .assign(loan_amnt_pct=lambda x : x['loan_amnt']/x.groupby(level=0)['loan_amnt'].sum(),
                              out_prncp_pct=lambda x : x['out_prncp']/x.groupby(level=0)['out_prncp'].sum())    
print(pay_data)

past_due = ['In Grace Period','Late (16-30 days)', 'Late (31-120 days)', 'Default','Charged Off']
delinquent = ['Late (16-30 days)', 'Late (31-120 days)', 'Default'] 
lost = ['Default']
chaeged_off = ['Charged Off']
analysis_data_1 = analysis_data.copy()
analysis_data_1['loan_status']  = analysis_data_1['loan_status'].map(lambda x :'Past Due' if x in past_due else x)
groupd_grade =  analysis_data_1.groupby(['grade','loan_status'])
pay_data_2 = groupd_grade.agg({'loan_amnt':'sum','out_prncp':'sum','total_rec_prncp':'sum','total_rec_int':'sum'}) \
                     .assign(loan_amnt_pct=lambda x : x['loan_amnt']/x.groupby(level=0)['loan_amnt'].sum(),
                              out_prncp_pct=lambda x : x['out_prncp']/x.groupby(level=0)['out_prncp'].sum())
print(pay_data_2)

past_due_data = pay_data_2.xs('Past Due', level=1)
past_due_data

f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)
x = past_due_data.index
y1 = past_due_data['loan_amnt_pct']
sns.barplot(x, y1, ax=ax1)
y2 = past_due_data['out_prncp_pct']
ax1.set_xlabel("")
ax1.set_ylabel("loan_amnt_pct")
sns.barplot(x, y2,ax=ax2)
ax2.set_ylabel("past_due_rate")
sns.despine(bottom=True)
plt.show()
```

# 信用风险模型
> 言归正传，所谓信用风险模型，简单的理解就是将历史发生的借贷行为抽象出来，我们相信有共同行为特征的一群人一定时间内在违约这件事情上具有相似的行为模式，因为我们从历史数据中提取各个维度的特征对应这些特征的履约表现，从而预测将来有这些特征的人的违约概率。这个里面就有几个关键的问题：

- 在预测违约之前首先要定义违约，
- 提取出对预测违约能起到作用特征变量，
- 提取特征的对象以及时间范围，
- 将特征与违约之间的关系进行拟合，
- 检验预测的效果。

> 回到LC这个案例：

- 我这里定义的违约是逾期15天以上，
- 特征变量的提取和处理，有时候又叫特征工程，实际上在传统的评分卡模型里这部分工作是最耗时间的，它需要业务经验和数据表现进行结合分析，不过现在越来越多的特征提取是通过机器学习的方法进行自动提取，本文实际上为了省时间也简单地利用了GBDT这个算法去评判特征变量的重要性，以及结合自己的业务判断进行
- 本来分析是基于2011年的放款数据，但是根据业务的常识，除了像欺诈类型的客户，通常情况下在放款一段时间后违约表现才可能充分和平稳。根据经验法则，小微贷款需要6个月左右的时间
- 本文主要采用传统的logistic regression进行线性拟合，
- 至于验证，分成两块，一块是样本内的验证，一块是样本外的验证，本文不对样本外的验证进行操作，实际上模型还没有出来就可以预知在样本外的验证效果会非常差，原因是本模型的取样并不是针对所有人群的随机抽样，而是将LC筛选通过后的客户作为样本，这里其实可以引出很重要的一个话题就是拒绝推论，不做展开了，后续再抽时间专门讲

1. 数据清理

> 2011年总共有21721条数据，每条数据52个属性。如何在这52个字段中提取出模型要使用的特征变量实际上可能是这篇文章里最耗时间的地方，数据预处理的部分前面几篇文章都有穿插着讲，本文不细讲，主要预处理是：1、贷后的相关变量除了target变量，其余直接剔除，因为贷后表现在客户申请时是没有的，如果进入模型实际上就成了未来变量；2、缺失率太高的变量直接剔除，本文是按65%的阈值来剔除的；3、数值变量中所有值方差太小接近常量的变量剔除，因为不能提供更多信息；4、按业务逻辑完全不可解释的变量直接剔除，5、分类变量中unique值大于20的直接剔除；6、将object类型数据转换成数值类型；7、缺失值单独当作一类，填充-999。



# 参考文献
1. [从风险管理说到数据分析](https://zhuanlan.zhihu.com/p/21394917)
2. [Lending Club Loan Data - Issued vs Declined](https://rstudio-pubs-static.s3.amazonaws.com/207029_0e87c2a4285b4819a93a10f001bc3beb.html)
3. [LendingClub信用评估体系](http://www.wtoutiao.com/p/fc9AuF.html)
4. [LendingClub商业模式解析：美国的P2P到底怎么玩？](https://xueqiu.com/9598793634/69610526)
5. [LendingClub巨亏原因](http://www.tmtpost.com/198008.html)
6. [2014年P2P小额信贷典型模式案例研究报告](https://github.com/xeebudong/resource/blob/master/ebooks/2014%E5%B9%B4P2P%E5%B0%8F%E9%A2%9D%E4%BF%A1%E8%B4%B7%E5%85%B8%E5%9E%8B%E6%A8%A1%E5%BC%8F%E6%A1%88%E4%BE%8B%E7%A0%94%E7%A9%B6%E6%8A%A5%E5%91%8A.pdf)
7. [LendingClub简史](https://lesliezhu.github.io/public/2014/01/10/p2p-03.html)
8. [Lending Club Loan DataAnalyze Lending Club's issued loans](https://www.kaggle.com/wendykan/lending-club-loan-data)

# 拓展
1. [评分卡模型](http://www.yangqiu.cn/holdyongquan/1353711.html)